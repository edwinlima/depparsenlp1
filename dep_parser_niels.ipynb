{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import word2vec \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as myfile:\n",
    "        f = myfile.readlines()\n",
    "        s_num = 0\n",
    "        i =0\n",
    "        sentence_s = []\n",
    "        tag_s = []\n",
    "        dep_s = []\n",
    "        s  = []   # sentence\n",
    "        p = []    # tag\n",
    "        d = []    # dependency\n",
    "        for l in f:\n",
    "            \n",
    "            v = l.replace('\\n','').split(\"\\t\")\n",
    "            v.append(s_num)\n",
    "            if len(l) != 1:\n",
    "                data.append(v)\n",
    "                dep = v[6] + '_' + v[7]\n",
    "                word = v[1].lower()\n",
    "                if any(char.isdigit() for char in word):\n",
    "                    word = 'NUM'       # replace numbers with NUM\n",
    "                s.append(word)\n",
    "                p.append(v[3])\n",
    "                d.append(dep)\n",
    "                i +=1\n",
    "            else:\n",
    "                sentence_s.append(s)\n",
    "                tag_s.append(p)\n",
    "                dep_s.append(d)\n",
    "                s_num +=1\n",
    "                s  = []\n",
    "                p = []\n",
    "                d = []\n",
    "        \n",
    "    return data, sentence_s, tag_s, dep_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  [['1', 'In', '_', 'IN', 'IN', '_', '45', 'prep', '_', '_', 0], ['2', 'an', '_', 'DT', 'DT', '_', '5', 'det', '_', '_', 0], ['3', 'Oct.', '_', 'NNP', 'NNP', '_', '5', 'nn', '_', '_', 0], ['4', '19', '_', 'CD', 'CD', '_', '5', 'num', '_', '_', 0], ['5', 'review', '_', 'NN', 'NN', '_', '1', 'pobj', '_', '_', 0]]\n",
      "words sentences:  [['rolls-royce', 'motor', 'cars', 'inc.', 'said', 'it', 'expects', 'its', 'u.s.', 'sales', 'to', 'remain', 'steady', 'at', 'about', 'NUM', 'cars', 'in', 'NUM', '.'], ['the', 'luxury', 'auto', 'maker', 'last', 'year', 'sold', 'NUM', 'cars', 'in', 'the', 'u.s.'], ['howard', 'mosher', ',', 'president', 'and', 'chief', 'executive', 'officer', ',', 'said', 'he', 'anticipates', 'growth', 'for', 'the', 'luxury', 'auto', 'maker', 'in', 'britain', 'and', 'europe', ',', 'and', 'in', 'far', 'eastern', 'markets', '.']]\n",
      "tags sentences:  [['NNP', 'NNP', 'NNPS', 'NNP', 'VBD', 'PRP', 'VBZ', 'PRP$', 'NNP', 'NNS', 'TO', 'VB', 'JJ', 'IN', 'IN', 'CD', 'NNS', 'IN', 'CD', '.'], ['DT', 'NN', 'NN', 'NN', 'JJ', 'NN', 'VBD', 'CD', 'NNS', 'IN', 'DT', 'NNP'], ['NNP', 'NNP', ',', 'NN', 'CC', 'JJ', 'NN', 'NN', ',', 'VBD', 'PRP', 'VBZ', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', 'CC', 'NNP', ',', 'CC', 'IN', 'JJ', 'JJ', 'NNS', '.']]\n",
      "dependencies:  [['4_nn', '4_nn', '4_nn', '5_nsubj', '0_root', '7_nsubj', '5_ccomp', '10_poss', '10_nn', '12_nsubj', '12_aux', '7_xcomp', '12_acomp', '12_prep', '16_quantmod', '17_num', '14_pobj', '12_prep', '18_pobj', '5_punct'], ['4_det', '4_nn', '4_nn', '7_nsubj', '6_amod', '7_tmod', '0_root', '9_num', '7_dobj', '7_prep', '12_det', '10_pobj'], ['2_nn', '10_nsubj', '2_punct', '2_appos', '4_cc', '8_amod', '8_nn', '4_conj', '2_punct', '0_root', '12_nsubj', '10_ccomp', '12_dobj', '13_prep', '18_det', '18_nn', '18_nn', '14_pobj', '13_prep', '19_pobj', '20_cc', '20_conj', '19_punct', '19_cc', '19_conj', '27_amod', '28_amod', '25_pobj', '10_punct']]\n"
     ]
    }
   ],
   "source": [
    "train_data, train_sentences, train_tags, train_dependencies = read_data('./data/train-stanford-raw.conll')\n",
    "dev_data, dev_sentences, dev_tags, dev_dependencies = read_data('./data/dev-stanford-raw.conll')\n",
    "test_data, test_sentences, test_tags, test_dependencies = read_data('./data/test-stanford-raw.conll')\n",
    "\n",
    "# create a full set of all the words in our train, test, and dev sets for word2vec model\n",
    "# in order to avoid unseen words during test and validation\n",
    "total_sentences = train_sentences + dev_sentences + test_sentences\n",
    "print('data: ', data[:5])\n",
    "print('words sentences: ', total_sentences[2:5])\n",
    "print('tags sentences: ', tags[2:5])\n",
    "print('dependencies: ', dependencies[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word2vec model\n",
      "model trained\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dep_parser_word2vec_total\"\n",
    "\n",
    "# train it:\n",
    "# print(\"training word2vec model\")\n",
    "# model = word2vec.Word2Vec(total_sentences,size=189, min_count=1) # here moeten we wat tweaken met de parameters\n",
    "# print(\"model trained\")\n",
    "# model.save(model_name)\n",
    "# print(\"model saved\")\n",
    "\n",
    "# or load it:\n",
    "model = Word2Vec.load(model_name)\n",
    "print(\"model loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V (length of training vocabulary): 35532\n",
      "[('beam', 0.9523080587387085), (\"'n'\", 0.9470729231834412), ('barry', 0.9401122331619263), ('marlboro', 0.939976155757904), ('aloft', 0.9398140907287598), ('colo.', 0.9389971494674683), ('manufacturer', 0.9372619986534119), ('constructed', 0.9367369413375854), ('angels', 0.9350725412368774), ('glossy', 0.9349611401557922)]\n",
      "cereal\n",
      "0.954927562839\n",
      "[ 0.03253329  0.29376748  0.42870235 -0.31171563 -0.44949016 -0.5051102\n",
      " -0.53029168 -0.36873311  0.06408304 -0.02383715  0.68958682  0.31396839\n",
      "  0.30426395 -0.28738719  0.20859465  0.45424727 -0.11529829  0.0015334\n",
      " -0.04299233 -0.12471952 -0.52828872 -0.11824053  0.37391958  0.3078886\n",
      "  0.39943048  0.42146483  0.50414109  0.21233779 -0.44621235  0.20821989\n",
      " -0.31146091 -0.1204848  -0.32732096 -0.11361341 -0.20991087 -0.51544493\n",
      " -0.07378293 -0.47551197  0.37150779 -0.22198907  0.6451869   0.25483611\n",
      "  0.26936471 -0.11964172 -0.03437093 -0.1712622   0.34830585  0.14544176\n",
      " -0.18600805  0.32915574  0.65152746 -0.16639298  0.50576556  0.18872985\n",
      "  0.25068954  0.20894329  0.11898699 -0.39643323 -0.44552663 -0.08712927\n",
      " -0.40556461  0.09727685 -0.1594474  -0.12646407 -0.28871056  0.21333955\n",
      " -0.25293636  0.02282144 -0.22530365 -0.07516725 -0.03546154 -0.10860643\n",
      " -0.24520764  0.71690428  0.06538964  0.06812638  0.0625902   0.1983761\n",
      " -0.02522858 -0.42909667  0.27805349  0.23773921  0.26462066 -0.3586221\n",
      "  0.62441492  0.03156432 -0.09575099  0.04357346 -0.21799707 -0.14386214\n",
      "  0.56131178 -0.09943483  0.52896899 -0.15703423  0.43490389 -0.83814293\n",
      " -0.24834323  0.12559029 -0.0592475  -0.03549263 -0.37601954  0.46932414\n",
      "  0.0062612   0.87049448 -0.20457004 -0.0705587  -0.19253866  0.09146405\n",
      "  0.73158807 -0.51083505 -0.66873354 -0.07344188 -0.26894885  0.68214196\n",
      "  0.69751847 -1.23392797 -0.43834811  0.04798706  0.31549543 -0.41825894\n",
      " -0.48682484 -0.65988225 -0.64643002 -0.0584436  -0.12661029  0.38496423\n",
      " -0.73021442  0.55287033 -0.31270036 -0.30893809 -0.0885734  -0.08676254\n",
      "  0.26852468  0.34392992  0.55302793  0.33493337 -0.55991709  0.1290735\n",
      "  0.35781139 -0.07829275 -0.05449573 -0.22169976 -0.09650581 -0.58966976\n",
      "  0.28239191 -0.6074096   0.07370292  0.25155261  0.34654018 -0.13198976\n",
      " -0.29552814 -0.30263472  0.14428167 -0.16279373  0.03057558 -0.04019608\n",
      "  0.33968028 -0.23247741  0.16622876  0.20144503  0.53279138 -0.30469748\n",
      "  0.19438019  0.27634025 -0.1067419  -0.10706893 -0.36153573  0.02340143\n",
      "  0.47526145  1.20401478  0.07079556 -0.53557485  0.29260507  0.11340433\n",
      " -0.22352563 -0.42523217  0.33220187  0.25000408 -0.14296791  0.29875922\n",
      "  0.08547492  0.1675434   0.09425761 -0.41700944  0.38377962  0.59538645\n",
      " -0.02965969  0.11686178  0.19178586]\n"
     ]
    }
   ],
   "source": [
    "vocab = model.vocab.keys()\n",
    "print(\"V (length of training vocabulary): \" + str(len(vocab)))\n",
    "print(\"most similar positive test: \")\n",
    "print(model.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "print(\"does not match test: \")\n",
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "print(\"word similarity test: \")\n",
    "print(model.similarity('woman', 'man'))\n",
    "print()\n",
    "print(model['computer'])  # raw numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
