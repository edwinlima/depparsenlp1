{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(dataname):\n",
    "    #reads in files, produces data structure with all actions\n",
    "        #does so by applying produce_rule_list to every sentence.\n",
    "        #for loop that sets actions to empty, calls p_r_l giving it\n",
    "        #the stack and buffer, actions and correct_parse, adds finished action list\n",
    "        #to new data file, for each sentence in the input data\n",
    "    #input: name of the data file with all parses. Run with data file in same directory.\n",
    "    #output: data file with all actions\n",
    "    file = open(dataname)\n",
    "    data = file.read()\n",
    "    correct_parses = correct_parse_list(data)\n",
    "    #gets rid of final whitespace\n",
    "    del correct_parses[len(correct_parses)-1]\n",
    "    \n",
    "    #iterates over all parses, producing action list for each\n",
    "    complete_rule_list = []\n",
    "    for sentence_parse in correct_parses:\n",
    "        stack = []\n",
    "#         print(len(sentence_parse))\n",
    "        buff = list(range(1,len(sentence_parse)+1))\n",
    "        actions = []\n",
    "        rule_list = produce_rule_list(stack, buff, actions, sentence_parse)\n",
    "        complete_rule_list.append(rule_list)\n",
    "\n",
    "    \n",
    "    return complete_rule_list\n",
    "\n",
    "def correct_parse_list(data):\n",
    "    #Turns data into a list of lists of lists with relevant information\n",
    "    correct_parse = data.split(\"\\n\\n\")\n",
    "    for index, paragraph in enumerate(correct_parse):\n",
    "        correct_parse[index] = paragraph.split(\"\\n\")\n",
    "    for paragraph in correct_parse:\n",
    "        for index, line in enumerate(paragraph):\n",
    "            paragraph[index] = line.split(\"\\t\")\n",
    "    return correct_parse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def produce_rule_list(stack, buff, actions, sentence_parse):\n",
    "    #recursive function that works through words in the sentence (stack/buffer)\n",
    "        #until only one word is left, creating the list of actions \n",
    "        #that was taken to parse it.\n",
    "    #input: stack, buffer, actions, correct parse\n",
    "    #output: actions with the actions taken for each buff/stack configuration\n",
    "    \n",
    "    #base case\n",
    "    if len(stack) == 1 and len(buff) == 0:\n",
    "        #actions.append([stack[:], \"empty\", \"R_arc\"])\n",
    "        actions.append([stack[0],-1, -1, \"R_root\"])\n",
    "        return actions\n",
    "\n",
    "    #If enough of the sentence is still left:\n",
    "    #If there is not enough material in the stack, shift:\n",
    "    if len(stack) == 0 :\n",
    "        #print('chose S - small stack')\n",
    "        actions.append([-1,-1,buff[0], \"S\"])\n",
    "        stack.append(buff[0])\n",
    "        del buff[0]        \n",
    "        return produce_rule_list(stack,buff,actions,sentence_parse)\n",
    "    if len(stack) == 1:\n",
    "        actions.append([-1,stack[-1],buff[0], \"S\"])\n",
    "        stack.append(buff[0])\n",
    "        del buff[0]\n",
    "        return produce_rule_list(stack,buff,actions,sentence_parse)\n",
    "    #If there are 2 or more words in the stack, decide which action to perform and perform it\n",
    "    if len(stack) > 1:\n",
    "        action = rule_decision(stack,buff,sentence_parse)\n",
    "        stack, buff, actions = action(stack,buff,actions, sentence_parse)\n",
    "        return produce_rule_list(stack,buff,actions,sentence_parse)\n",
    "    \n",
    "\n",
    "def rule_decision(stack, buff, sentence_parse):\n",
    "    #determines which action to apply\n",
    "    #input: words on stack, words on buff, correct parse\n",
    "    #output: one of three methods, Shift(), L_arc(), R_arc()\n",
    "\n",
    "    #TODO: find ids/heads (index [6]) from stack and sentence_parse\n",
    "    s1 = stack[-2]\n",
    "    head_of_s1 = int(sentence_parse[s1-1][6])\n",
    "    s2 = stack[-1]\n",
    "    head_of_s2 = int(sentence_parse[s2-1][6])\n",
    "    \n",
    "    #L arcs can always be applied if possible\n",
    "    if head_of_s1 == s2:\n",
    "        action = L_arc\n",
    "        #print('chose L')\n",
    "    else:\n",
    "        #R arcs can only be applied if there is no word in the buffer which has the last word in the stack as a head\n",
    "        if head_of_s2 == s1:\n",
    "            buff_heads = [int(sentence_parse[x-1][6]) for x in buff]\n",
    "            if s2 in buff_heads:\n",
    "                action = Shift\n",
    "                #print('chose S - s2 in buffheads')\n",
    "            else:\n",
    "                action = R_arc\n",
    "                #print('chose R')\n",
    "        #if there is no match between s1 and s2, simply shift another word from the buffer\n",
    "        else:\n",
    "            action = Shift\n",
    "            #print('chose S - no matching s1s2')\n",
    "\n",
    "    return action\n",
    "\n",
    "#The following methods perform an arc or shift. These can be changed if more data is needed in the network.\n",
    "\n",
    "def L_arc(stack, buff, actions, sentence_parse):\n",
    "    #removes second to last item from stack, writes action to actions\n",
    "    #input: stack and actions\n",
    "    #output: new stack and actions with one L_arc line\n",
    "    #s1, s2, b1, action\n",
    "    s1 = int(stack[-2])\n",
    "    s2 = int(stack[-1])\n",
    "    b1 = int(stack[0])\n",
    "    relation = sentence_parse[s1-1][7]\n",
    "    #actions.append([stack[:], buff[:], \"L_arc\"])\n",
    "    actions.append([s1,s2,b1, \"L\"+\"_\"+relation])\n",
    "    del stack[-2]\n",
    "    return stack, buff, actions\n",
    "\n",
    "\n",
    "\n",
    "def R_arc(stack, buff, actions, sentence_parse):\n",
    "    #removes last item from the stack, writes action to actions\n",
    "    #input: stack and actions\n",
    "    #output: new stack and actions with one R_arc line\n",
    "    #s1, s2, b1, action\n",
    "    s1 = int(stack[-2])\n",
    "    s2 = int(stack[-1])\n",
    "    b1 = int(stack[0])\n",
    "    relation = sentence_parse[s2-1][7]\n",
    "    #actions.append([stack[:], buff[:], \"R_arc\"])\n",
    "    actions.append([s1,s2,b1, \"R\"+\"_\"+relation])\n",
    "    del stack[-1]\n",
    "    return stack, buff, actions\n",
    "\n",
    "\n",
    "\n",
    "def Shift(stack, buff, actions, sentence_parse):\n",
    "    #moves an item from the buff to the stack, writes action to actions\n",
    "    #input: stack, buff and actions\n",
    "    #output: new stack and actions with one extra shift line\n",
    "    #s1, s2, b1, action\n",
    "    s1 = int(stack[-2])\n",
    "    s2 = int(stack[-1])\n",
    "    b1 = int(stack[0])\n",
    "    #actions.append([stack[:], buff[:], \"Shift\"])\n",
    "    actions.append([s1,s2,b1, \"S\"])\n",
    "    stack.append(buff[0])\n",
    "    del buff[0]\n",
    "    return stack, buff, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "action_data = process_data('data/train-stanford-raw.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, 1, 'S']\n",
      "[-1, 1, 2, 'S']\n",
      "[1, 2, 1, 'S']\n",
      "[2, 3, 1, 'L_aux']\n",
      "[1, 3, 1, 'L_nsubj']\n",
      "[-1, 3, 4, 'S']\n",
      "[3, 4, 3, 'R_iobj']\n",
      "[-1, 3, 5, 'S']\n",
      "[3, 5, 3, 'S']\n",
      "[5, 6, 3, 'L_det']\n",
      "[3, 6, 3, 'S']\n",
      "[6, 7, 3, 'S']\n",
      "[7, 8, 3, 'L_aux']\n",
      "[6, 8, 3, 'S']\n",
      "[8, 9, 3, 'S']\n",
      "[9, 10, 3, 'L_det']\n",
      "[8, 10, 3, 'R_dobj']\n",
      "[6, 8, 3, 'S']\n",
      "[8, 11, 3, 'R_cc']\n",
      "[6, 8, 3, 'S']\n",
      "[8, 12, 3, 'S']\n",
      "[12, 13, 3, 'L_advmod']\n",
      "[8, 13, 3, 'S']\n",
      "[13, 14, 3, 'S']\n",
      "[14, 15, 3, 'S']\n",
      "[15, 16, 3, 'L_amod']\n",
      "[14, 16, 3, 'L_det']\n",
      "[13, 16, 3, 'R_dobj']\n",
      "[8, 13, 3, 'R_conj']\n",
      "[6, 8, 3, 'R_infmod']\n",
      "[3, 6, 3, 'R_dobj']\n",
      "[-1, 3, 17, 'S']\n",
      "[3, 17, 3, 'R_punct']\n",
      "[3, -1, -1, 'R_root']\n"
     ]
    }
   ],
   "source": [
    "for action in action_data[-1]:\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39832\n"
     ]
    }
   ],
   "source": [
    "print(len(action_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
