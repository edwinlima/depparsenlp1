{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import word2vec \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as myfile:\n",
    "        f = myfile.readlines()\n",
    "        s_num = 0\n",
    "        i =0\n",
    "        sentence_s = []\n",
    "        tag_s = []\n",
    "        dep_s = []\n",
    "        s  = []   # sentence\n",
    "        p = []    # tag\n",
    "        d = []    # dependency\n",
    "        for l in f:\n",
    "            \n",
    "            v = l.replace('\\n','').split(\"\\t\")\n",
    "            v.append(s_num)\n",
    "            if len(l) != 1:\n",
    "                data.append(v)\n",
    "                dep = v[6] + '_' + v[7]\n",
    "                word = v[1].lower()\n",
    "                if any(char.isdigit() for char in word):\n",
    "                    word = 'NUM'       # replace numbers with NUM\n",
    "                s.append(word)\n",
    "                p.append(v[3])\n",
    "                d.append(dep)\n",
    "                i +=1\n",
    "            else:\n",
    "                sentence_s.append(s)\n",
    "                tag_s.append(p)\n",
    "                dep_s.append(d)\n",
    "                s_num +=1\n",
    "                s  = []\n",
    "                p = []\n",
    "                d = []\n",
    "        \n",
    "    return data, sentence_s, tag_s, dep_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  [['1', 'In', '_', 'IN', 'IN', '_', '45', 'prep', '_', '_', 0], ['2', 'an', '_', 'DT', 'DT', '_', '5', 'det', '_', '_', 0], ['3', 'Oct.', '_', 'NNP', 'NNP', '_', '5', 'nn', '_', '_', 0], ['4', '19', '_', 'CD', 'CD', '_', '5', 'num', '_', '_', 0], ['5', 'review', '_', 'NN', 'NN', '_', '1', 'pobj', '_', '_', 0]]\n",
      "words sentences:  [['rolls-royce', 'motor', 'cars', 'inc.', 'said', 'it', 'expects', 'its', 'u.s.', 'sales', 'to', 'remain', 'steady', 'at', 'about', 'NUM', 'cars', 'in', 'NUM', '.'], ['the', 'luxury', 'auto', 'maker', 'last', 'year', 'sold', 'NUM', 'cars', 'in', 'the', 'u.s.'], ['howard', 'mosher', ',', 'president', 'and', 'chief', 'executive', 'officer', ',', 'said', 'he', 'anticipates', 'growth', 'for', 'the', 'luxury', 'auto', 'maker', 'in', 'britain', 'and', 'europe', ',', 'and', 'in', 'far', 'eastern', 'markets', '.']]\n",
      "tags sentences:  [['NNP', 'NNP', 'NNPS', 'NNP', 'VBD', 'PRP', 'VBZ', 'PRP$', 'NNP', 'NNS', 'TO', 'VB', 'JJ', 'IN', 'IN', 'CD', 'NNS', 'IN', 'CD', '.'], ['DT', 'NN', 'NN', 'NN', 'JJ', 'NN', 'VBD', 'CD', 'NNS', 'IN', 'DT', 'NNP'], ['NNP', 'NNP', ',', 'NN', 'CC', 'JJ', 'NN', 'NN', ',', 'VBD', 'PRP', 'VBZ', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'IN', 'NNP', 'CC', 'NNP', ',', 'CC', 'IN', 'JJ', 'JJ', 'NNS', '.']]\n",
      "dependencies:  [['4_nn', '4_nn', '4_nn', '5_nsubj', '0_root', '7_nsubj', '5_ccomp', '10_poss', '10_nn', '12_nsubj', '12_aux', '7_xcomp', '12_acomp', '12_prep', '16_quantmod', '17_num', '14_pobj', '12_prep', '18_pobj', '5_punct'], ['4_det', '4_nn', '4_nn', '7_nsubj', '6_amod', '7_tmod', '0_root', '9_num', '7_dobj', '7_prep', '12_det', '10_pobj'], ['2_nn', '10_nsubj', '2_punct', '2_appos', '4_cc', '8_amod', '8_nn', '4_conj', '2_punct', '0_root', '12_nsubj', '10_ccomp', '12_dobj', '13_prep', '18_det', '18_nn', '18_nn', '14_pobj', '13_prep', '19_pobj', '20_cc', '20_conj', '19_punct', '19_cc', '19_conj', '27_amod', '28_amod', '25_pobj', '10_punct']]\n"
     ]
    }
   ],
   "source": [
    "train_data, train_sentences, train_tags, train_dependencies = read_data('./data/train-stanford-raw.conll')\n",
    "dev_data, dev_sentences, dev_tags, dev_dependencies = read_data('./data/dev-stanford-raw.conll')\n",
    "test_data, test_sentences, test_tags, test_dependencies = read_data('./data/test-stanford-raw.conll')\n",
    "\n",
    "# create a full set of all the words in our train, test, and dev sets for word2vec model\n",
    "# in order to avoid unseen words during test and validation\n",
    "total_sentences = train_sentences + dev_sentences + test_sentences\n",
    "print('data: ', data[:5])\n",
    "print('words sentences: ', total_sentences[2:5])\n",
    "print('tags sentences: ', tags[2:5])\n",
    "print('dependencies: ', dependencies[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word2vec model\n",
      "model trained\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dep_parser_word2vec_total\"\n",
    "\n",
    "# train it:\n",
    "# print(\"training word2vec model\")\n",
    "# model = word2vec.Word2Vec(total_sentences,size=189, min_count=1) # here moeten we wat tweaken met de parameters\n",
    "# print(\"model trained\")\n",
    "# model.save(model_name)\n",
    "# print(\"model saved\")\n",
    "\n",
    "# or load it:\n",
    "model = Word2Vec.load(model_name)\n",
    "print(\"model loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V (length of training vocabulary): 35532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.03253329,  0.29376748,  0.42870235, -0.31171563, -0.44949016,\n",
       "       -0.5051102 , -0.53029168, -0.36873311,  0.06408304, -0.02383715,\n",
       "        0.68958682,  0.31396839,  0.30426395, -0.28738719,  0.20859465,\n",
       "        0.45424727, -0.11529829,  0.0015334 , -0.04299233, -0.12471952,\n",
       "       -0.52828872, -0.11824053,  0.37391958,  0.3078886 ,  0.39943048,\n",
       "        0.42146483,  0.50414109,  0.21233779, -0.44621235,  0.20821989,\n",
       "       -0.31146091, -0.1204848 , -0.32732096, -0.11361341, -0.20991087,\n",
       "       -0.51544493, -0.07378293, -0.47551197,  0.37150779, -0.22198907,\n",
       "        0.6451869 ,  0.25483611,  0.26936471, -0.11964172, -0.03437093,\n",
       "       -0.1712622 ,  0.34830585,  0.14544176, -0.18600805,  0.32915574,\n",
       "        0.65152746, -0.16639298,  0.50576556,  0.18872985,  0.25068954,\n",
       "        0.20894329,  0.11898699, -0.39643323, -0.44552663, -0.08712927,\n",
       "       -0.40556461,  0.09727685, -0.1594474 , -0.12646407, -0.28871056,\n",
       "        0.21333955, -0.25293636,  0.02282144, -0.22530365, -0.07516725,\n",
       "       -0.03546154, -0.10860643, -0.24520764,  0.71690428,  0.06538964,\n",
       "        0.06812638,  0.0625902 ,  0.1983761 , -0.02522858, -0.42909667,\n",
       "        0.27805349,  0.23773921,  0.26462066, -0.3586221 ,  0.62441492,\n",
       "        0.03156432, -0.09575099,  0.04357346, -0.21799707, -0.14386214,\n",
       "        0.56131178, -0.09943483,  0.52896899, -0.15703423,  0.43490389,\n",
       "       -0.83814293, -0.24834323,  0.12559029, -0.0592475 , -0.03549263,\n",
       "       -0.37601954,  0.46932414,  0.0062612 ,  0.87049448, -0.20457004,\n",
       "       -0.0705587 , -0.19253866,  0.09146405,  0.73158807, -0.51083505,\n",
       "       -0.66873354, -0.07344188, -0.26894885,  0.68214196,  0.69751847,\n",
       "       -1.23392797, -0.43834811,  0.04798706,  0.31549543, -0.41825894,\n",
       "       -0.48682484, -0.65988225, -0.64643002, -0.0584436 , -0.12661029,\n",
       "        0.38496423, -0.73021442,  0.55287033, -0.31270036, -0.30893809,\n",
       "       -0.0885734 , -0.08676254,  0.26852468,  0.34392992,  0.55302793,\n",
       "        0.33493337, -0.55991709,  0.1290735 ,  0.35781139, -0.07829275,\n",
       "       -0.05449573, -0.22169976, -0.09650581, -0.58966976,  0.28239191,\n",
       "       -0.6074096 ,  0.07370292,  0.25155261,  0.34654018, -0.13198976,\n",
       "       -0.29552814, -0.30263472,  0.14428167, -0.16279373,  0.03057558,\n",
       "       -0.04019608,  0.33968028, -0.23247741,  0.16622876,  0.20144503,\n",
       "        0.53279138, -0.30469748,  0.19438019,  0.27634025, -0.1067419 ,\n",
       "       -0.10706893, -0.36153573,  0.02340143,  0.47526145,  1.20401478,\n",
       "        0.07079556, -0.53557485,  0.29260507,  0.11340433, -0.22352563,\n",
       "       -0.42523217,  0.33220187,  0.25000408, -0.14296791,  0.29875922,\n",
       "        0.08547492,  0.1675434 ,  0.09425761, -0.41700944,  0.38377962,\n",
       "        0.59538645, -0.02965969,  0.11686178,  0.19178586], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = model.vocab.keys()\n",
    "print(\"V (length of training vocabulary): \" + str(len(vocab)))\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "model.similarity('woman', 'man')\n",
    "model['computer']  # raw numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
