{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(dataname):\n",
    "    #reads in files, produces data structure with all actions\n",
    "        #does so by applying produce_rule_list to every sentence.\n",
    "        #for loop that sets actions to empty, calls p_r_l giving it\n",
    "        #the stack and buffer, actions and correct_parse, adds finished action list\n",
    "        #to new data file, for each sentence in the input data\n",
    "    #input: name of the data file with all parses. Run with data file in same directory.\n",
    "    #output: data file with all actions\n",
    "    file = open(dataname)\n",
    "    data = file.read()\n",
    "    correct_parses = correct_parse_list(data)\n",
    "    #gets rid of final whitespace\n",
    "    del correct_parses[len(correct_parses)-1]\n",
    "    \n",
    "    #iterates over all parses, producing action list for each\n",
    "    complete_rule_list = []\n",
    "    arc_dict = {'Shift':0,'L_root':1,'R_root':2}\n",
    "    for sentence_parse in correct_parses:\n",
    "        stack = []\n",
    "#         print(len(sentence_parse))\n",
    "        buff = list(range(1,len(sentence_parse)+1))\n",
    "        actions = []\n",
    "        rule_list, arc_dict = produce_rule_list(stack, buff, actions, sentence_parse, arc_dict)\n",
    "        complete_rule_list.append(rule_list)\n",
    "\n",
    "    \n",
    "    return complete_rule_list, arc_dict\n",
    "\n",
    "def correct_parse_list(data):\n",
    "    #Turns data into a list of lists of lists with relevant information\n",
    "    correct_parse = data.split(\"\\n\\n\")\n",
    "    for index, paragraph in enumerate(correct_parse):\n",
    "        correct_parse[index] = paragraph.split(\"\\n\")\n",
    "    for paragraph in correct_parse:\n",
    "        for index, line in enumerate(paragraph):\n",
    "            paragraph[index] = line.split(\"\\t\")\n",
    "    return correct_parse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def produce_rule_list(stack, buff, actions, sentence_parse, arc_dict):\n",
    "    #recursive function that works through words in the sentence (stack/buffer)\n",
    "        #until only one word is left, creating the list of actions \n",
    "        #that was taken to parse it.\n",
    "    #input: stack, buffer, actions, correct parse\n",
    "    #output: actions with the actions taken for each buff/stack configuration\n",
    "    \n",
    "    #base case\n",
    "    if len(stack) == 1 and len(buff) == 0:\n",
    "        #actions.append([stack[:], \"empty\", \"R_arc\"])\n",
    "        actions.append([-1,stack[0], -1, 2])\n",
    "        return actions, arc_dict\n",
    "\n",
    "    #If enough of the sentence is still left:\n",
    "    #If there is not enough material in the stack, shift:\n",
    "    if len(stack) == 0 :\n",
    "        #print('chose S - small stack')\n",
    "        actions.append([-1,-1,buff[0], 0])\n",
    "        stack.append(buff[0])\n",
    "        del buff[0]        \n",
    "        return produce_rule_list(stack,buff,actions,sentence_parse, arc_dict)\n",
    "    if len(stack) == 1:\n",
    "        actions.append([-1,stack[-1],buff[0], 0])\n",
    "        stack.append(buff[0])\n",
    "        del buff[0]\n",
    "        return produce_rule_list(stack,buff,actions,sentence_parse, arc_dict)\n",
    "    #If there are 2 or more words in the stack, decide which action to perform and perform it\n",
    "    if len(stack) > 1:\n",
    "        action = rule_decision(stack,buff,sentence_parse)\n",
    "        stack, buff, actions, arc_dict = action(stack,buff,actions, sentence_parse, arc_dict)\n",
    "        return produce_rule_list(stack,buff,actions,sentence_parse, arc_dict)\n",
    "    \n",
    "\n",
    "def rule_decision(stack, buff, sentence_parse):\n",
    "    #determines which action to apply\n",
    "    #input: words on stack, words on buff, correct parse\n",
    "    #output: one of three methods, Shift(), L_arc(), R_arc()\n",
    "\n",
    "    #TODO: find ids/heads (index [6]) from stack and sentence_parse\n",
    "    s1 = stack[-2]\n",
    "    head_of_s1 = int(sentence_parse[s1-1][6])\n",
    "    s2 = stack[-1]\n",
    "    head_of_s2 = int(sentence_parse[s2-1][6])\n",
    "    \n",
    "    #L arcs can always be applied if possible\n",
    "    if head_of_s1 == s2:\n",
    "        action = L_arc\n",
    "        #print('chose L')\n",
    "    else:\n",
    "        #R arcs can only be applied if there is no word in the buffer which has the last word in the stack as a head\n",
    "        if head_of_s2 == s1:\n",
    "            buff_heads = [int(sentence_parse[x-1][6]) for x in buff]\n",
    "            if s2 in buff_heads:\n",
    "                action = Shift\n",
    "                #print('chose S - s2 in buffheads')\n",
    "            else:\n",
    "                action = R_arc\n",
    "                #print('chose R')\n",
    "        #if there is no match between s1 and s2, simply shift another word from the buffer\n",
    "        else:\n",
    "            action = Shift\n",
    "            #print('chose S - no matching s1s2')\n",
    "\n",
    "    return action\n",
    "\n",
    "#The following methods perform an arc or shift. These can be changed if more data is needed in the network.\n",
    "\n",
    "def L_arc(stack, buff, actions, sentence_parse, arc_dict):\n",
    "    #removes second to last item from stack, writes action to actions\n",
    "    #input: stack and actions\n",
    "    #output: new stack and actions with one L_arc line\n",
    "    #s1, s2, b1, action\n",
    "    s1 = int(stack[-2])\n",
    "    s2 = int(stack[-1])\n",
    "    b1 = int(stack[0])\n",
    "    relation = \"L_\"+sentence_parse[s1-1][7]\n",
    "\n",
    "    if relation not in arc_dict:\n",
    "        maximum = max(arc_dict, key=arc_dict.get)\n",
    "        arc_dict['L_'+relation[2:]] = arc_dict[maximum]+1\n",
    "        arc_dict['R_'+relation[2:]] = arc_dict[maximum]+2\n",
    "    \n",
    "\n",
    "    actions.append([s1,s2,b1, arc_dict[relation]])\n",
    "    del stack[-2]\n",
    "    return stack, buff, actions, arc_dict\n",
    "\n",
    "\n",
    "\n",
    "def R_arc(stack, buff, actions, sentence_parse, arc_dict):\n",
    "    #removes last item from the stack, writes action to actions\n",
    "    #input: stack and actions\n",
    "    #output: new stack and actions with one R_arc line\n",
    "    #s1, s2, b1, action\n",
    "    s1 = int(stack[-2])\n",
    "    s2 = int(stack[-1])\n",
    "    b1 = int(stack[0])\n",
    "    relation = \"R_\"+sentence_parse[s2-1][7]\n",
    "\n",
    "    if relation not in arc_dict:\n",
    "        maximum = max(arc_dict, key=arc_dict.get)\n",
    "        arc_dict['L_'+relation[2:]] = arc_dict[maximum]+1\n",
    "        arc_dict['R_'+relation[2:]] = arc_dict[maximum]+2 \n",
    "    \n",
    "    actions.append([s1,s2,b1, arc_dict[relation]])\n",
    "    del stack[-1]\n",
    "    return stack, buff, actions, arc_dict\n",
    "\n",
    "\n",
    "\n",
    "def Shift(stack, buff, actions, sentence_parse, arc_dict):\n",
    "    #moves an item from the buff to the stack, writes action to actions\n",
    "    #input: stack, buff and actions\n",
    "    #output: new stack and actions with one extra shift line\n",
    "    #s1, s2, b1, action\n",
    "    s1 = int(stack[-2])\n",
    "    s2 = int(stack[-1])\n",
    "    b1 = int(stack[0])\n",
    "    #actions.append([stack[:], buff[:], \"Shift\"])\n",
    "    actions.append([s1,s2,b1, 0])\n",
    "    stack.append(buff[0])\n",
    "    del buff[0]\n",
    "    return stack, buff, actions, arc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "action_data, arc_dict = process_data('./data/train-stanford-raw.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "{'R_acomp': 42, 'L_ccomp': 47, 'L_csubj': 73, 'R_rcmod': 62, 'L_conj': 27, 'R_dep': 30, 'L_punct': 9, 'L_expl': 87, 'R_nsubjpass': 38, 'R_num': 4, 'L_tmod': 49, 'L_preconj': 91, 'L_number': 79, 'R_prt': 82, 'R_mark': 68, 'L_num': 3, 'R_det': 8, 'L_appos': 51, 'L_predet': 71, 'R_nn': 6, 'R_prep': 18, 'L_det': 7, 'L_csubjpass': 97, 'L_possessive': 11, 'L_acomp': 41, 'Shift': 0, 'L_prt': 81, 'R_auxpass': 36, 'L_abbrev': 93, 'R_dobj': 24, 'L_parataxis': 65, 'R_abbrev': 94, 'L_iobj': 83, 'L_dep': 29, 'L_pobj': 15, 'R_preconj': 92, 'L_quantmod': 43, 'L_poss': 13, 'L_pcomp': 59, 'L_partmod': 31, 'R_cc': 26, 'R_parataxis': 66, 'R_appos': 52, 'L_complm': 63, 'R_number': 80, 'R_csubjpass': 98, 'L_advmod': 33, 'R_poss': 14, 'L_advcl': 69, 'L_rel': 85, 'R_advmod': 34, 'R_quantmod': 44, 'R_possessive': 12, 'L_cop': 95, 'R_complm': 64, 'L_amod': 19, 'R_expl': 88, 'R_advcl': 70, 'L_infmod': 57, 'L_rcmod': 61, 'L_aux': 39, 'R_mwe': 76, 'R_aux': 40, 'R_xcomp': 46, 'R_cop': 96, 'L_mwe': 75, 'L_nsubjpass': 37, 'L_purpcl': 89, 'L_cc': 25, 'R_infmod': 58, 'R_iobj': 84, 'R_purpcl': 90, 'L_nn': 5, 'L_prep': 17, 'R_csubj': 74, 'L_root': 1, 'R_ccomp': 48, 'R_amod': 20, 'R_pobj': 16, 'R_punct': 10, 'R_conj': 28, 'L_attr': 77, 'R_nsubj': 22, 'L_neg': 55, 'L_nsubj': 21, 'R_predet': 72, 'R_npadvmod': 54, 'R_attr': 78, 'L_xcomp': 45, 'L_auxpass': 35, 'R_root': 2, 'R_rel': 86, 'L_npadvmod': 53, 'R_tmod': 50, 'L_mark': 67, 'R_pcomp': 60, 'L_dobj': 23, 'R_neg': 56, 'R_partmod': 32}\n",
      "[-1, -1, 1, 0]\n",
      "[-1, 1, 2, 0]\n",
      "[1, 2, 1, 0]\n",
      "[2, 3, 1, 0]\n",
      "[3, 4, 1, 0]\n",
      "[4, 5, 1, 3]\n",
      "[3, 5, 1, 5]\n",
      "[2, 5, 1, 7]\n",
      "[1, 5, 1, 0]\n",
      "[5, 6, 1, 0]\n",
      "[6, 7, 1, 0]\n",
      "[7, 8, 1, 0]\n",
      "[8, 9, 1, 7]\n",
      "[7, 9, 1, 9]\n",
      "[6, 9, 1, 0]\n",
      "[9, 10, 1, 10]\n",
      "[6, 9, 1, 0]\n",
      "[9, 11, 1, 0]\n",
      "[11, 12, 1, 0]\n",
      "[12, 13, 1, 12]\n",
      "[11, 12, 1, 0]\n",
      "[12, 14, 1, 0]\n",
      "[14, 15, 1, 5]\n",
      "[12, 15, 1, 13]\n",
      "[11, 15, 1, 16]\n",
      "[9, 11, 1, 18]\n",
      "[6, 9, 1, 16]\n",
      "[5, 6, 1, 18]\n",
      "[1, 5, 1, 0]\n",
      "[5, 16, 1, 0]\n",
      "[16, 17, 1, 0]\n",
      "[17, 18, 1, 0]\n",
      "[18, 19, 1, 19]\n",
      "[17, 19, 1, 0]\n",
      "[19, 20, 1, 21]\n",
      "[17, 20, 1, 9]\n",
      "[16, 20, 1, 9]\n",
      "[5, 20, 1, 0]\n",
      "[20, 21, 1, 0]\n",
      "[21, 22, 1, 7]\n",
      "[20, 22, 1, 24]\n",
      "[5, 20, 1, 0]\n",
      "[20, 23, 1, 0]\n",
      "[23, 24, 1, 0]\n",
      "[24, 25, 1, 5]\n",
      "[23, 25, 1, 16]\n",
      "[20, 23, 1, 18]\n",
      "[5, 20, 1, 0]\n",
      "[20, 26, 1, 10]\n",
      "[5, 20, 1, 0]\n",
      "[20, 27, 1, 10]\n",
      "[5, 20, 1, 0]\n",
      "[20, 28, 1, 0]\n",
      "[28, 29, 1, 26]\n",
      "[20, 28, 1, 0]\n",
      "[28, 30, 1, 28]\n",
      "[20, 28, 1, 30]\n",
      "[5, 20, 1, 0]\n",
      "[20, 31, 1, 10]\n",
      "[5, 20, 1, 30]\n",
      "[1, 5, 1, 16]\n",
      "[-1, 1, 32, 0]\n",
      "[1, 32, 1, 0]\n",
      "[32, 33, 1, 0]\n",
      "[33, 34, 1, 7]\n",
      "[32, 34, 1, 0]\n",
      "[34, 35, 1, 0]\n",
      "[35, 36, 1, 16]\n",
      "[34, 35, 1, 18]\n",
      "[32, 34, 1, 0]\n",
      "[34, 37, 1, 10]\n",
      "[32, 34, 1, 0]\n",
      "[34, 38, 1, 0]\n",
      "[38, 39, 1, 0]\n",
      "[39, 40, 1, 0]\n",
      "[40, 41, 1, 5]\n",
      "[39, 41, 1, 16]\n",
      "[38, 39, 1, 18]\n",
      "[34, 38, 1, 32]\n",
      "[32, 34, 1, 0]\n",
      "[34, 42, 1, 10]\n",
      "[32, 34, 1, 0]\n",
      "[34, 43, 1, 0]\n",
      "[43, 44, 1, 0]\n",
      "[44, 45, 1, 33]\n",
      "[43, 45, 1, 35]\n",
      "[34, 45, 1, 37]\n",
      "[32, 45, 1, 9]\n",
      "[1, 45, 1, 17]\n",
      "[-1, 45, 46, 0]\n",
      "[45, 46, 45, 0]\n",
      "[46, 47, 45, 0]\n",
      "[47, 48, 45, 5]\n",
      "[46, 48, 45, 16]\n",
      "[45, 46, 45, 18]\n",
      "[-1, 45, 49, 0]\n",
      "[45, 49, 45, 10]\n",
      "[-1, 45, -1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(len(arc_dict.keys()))\n",
    "print(arc_dict)\n",
    "for line in action_data[0]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
